version: "3.9"

services:
  # -------------------------
  # Next.js frontend (apps/web)
  # -------------------------
  web:
    build:
      context: ..
      dockerfile: infra/docker/web.Dockerfile
    working_dir: /app
    env_file:
      - ../.env
    environment:
      NODE_ENV: development
      # Frontend talks to the API service by container name
      NEXT_PUBLIC_API_URL: http://api:8000
      # Supabase URL is still public, comes from .env
      NEXT_PUBLIC_SUPABASE_URL: ${NEXT_PUBLIC_SUPABASE_URL}
    ports:
      - "3000:3000"
    depends_on:
      - api
    volumes:
      - ..:/app:cached
    command: pnpm --filter web dev

  # -------------------------
  # Express API (services/api)
  # -------------------------
  api:
    build:
      context: ..
      dockerfile: infra/docker/api.Dockerfile
    working_dir: /app
    env_file:
      - ../.env
    environment:
      PORT: 8000
      # API talks to AI orchestrator by container name
      AI_ORCHESTRATOR_URL: http://ai:8001
      NEXT_PUBLIC_SUPABASE_URL: ${NEXT_PUBLIC_SUPABASE_URL}
      SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_ROLE_KEY}
    ports:
      - "8000:8000"
    depends_on:
      - ai
    volumes:
      - ..:/app:cached
    command: pnpm --filter api dev

  # -------------------------
  # AI Orchestrator (FastAPI)
  # -------------------------
  ai:
    build:
      context: ..
      dockerfile: infra/docker/ai-orchestrator.Dockerfile
    working_dir: /app
    env_file:
      - ../.env
    environment:
      LANGFLOW_BASE_URL: http://langflow:7860
      LANGFLOW_GENERATE_FLOW_ID: ${LANGFLOW_GENERATE_FLOW_ID:-}
      LANGFLOW_ADAPT_FLOW_ID: ${LANGFLOW_ADAPT_FLOW_ID:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    ports:
      - "8001:8001"
    depends_on:
      - langflow
    volumes:
      - ..:/app:cached
    command: uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload

  # -------------------------
  # Langflow (AI flow builder)
  # -------------------------
  langflow:
    image: langflowai/langflow:latest
    environment:
      LANGFLOW_HOST: 0.0.0.0
      LANGFLOW_PORT: 7860
      # Lets Langflow call OpenAI directly
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    ports:
      - "7860:7860"
    volumes:
      # Persist flows so they survive container rebuilds
      - ../langflow:/app/langflow

  # -------------------------
  # Scheduler / Cron worker
  # -------------------------
  scheduler:
    build:
      context: ..
      dockerfile: infra/docker/scheduler.Dockerfile
    working_dir: /app
    env_file:
      - ../.env
    environment:
      NODE_ENV: development
      # Scheduler calls the API for streaks/badges, etc.
      API_BASE_URL: http://api:8000
    depends_on:
      - api
    volumes:
      - ..:/app:cached
    command: pnpm --filter scheduler dev

networks:
  default:
    name: pulse-dev
